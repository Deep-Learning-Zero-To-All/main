{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Array with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "t=np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t:  1\n",
      "Shape of t:  (7,)\n"
     ]
    }
   ],
   "source": [
    "print('Rank of t: ', t.ndim)\n",
    "print('Shape of t: ', t.shape) # 7개의 element가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t[0] t[1] t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4,-1] =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:] =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "print('t[0] t[1] t[-1] = ',t[0],t[1],t[-1]) #Element\n",
    "print('t[2:5] t[4,-1] = ',t[2:5],t[4:-1]) #Slicing\n",
    "print('t[:2] t[3:] = ',t[:2],t[3:]) #Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Array with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "t=np.array([[1., 2., 3.],[4., 5., 6.],[7., 8., 9.,], [10., 11., 12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t:  2\n",
      "Shape of t:  (4, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Rank of t: ',t.ndim) #2차 확인\n",
    "print('Shape of t: ' ,t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "t=torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) #rank\n",
    "print(t.shape) #shape\n",
    "print(t.size()) #shape\n",
    "print(t[0],t[1],t[-1]) #Element\n",
    "print(t[2:5],t[4:-1]) #Slicing\n",
    "print(t[:2],t[3:]) #Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "t=torch.FloatTensor([[1., 2., 3.],\n",
    "                    [4., 5., 6.],\n",
    "                    [7., 8., 9.],\n",
    "                    [10., 11., 12.]\n",
    "                    ])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) #rank\n",
    "print(t.size()) #shape\n",
    "print(t[:,1])\n",
    "print(t[:,1].size())\n",
    "print(t[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "- 사칙연산시에 차원이 일치해야한다는 규칙이 있다.\n",
    "- 하지만 불가피하게 차원이 일치하지 않는 텐서의 사칙연산을 해야 한다.\n",
    "- 그럴 때 자동적으로 차원을 맞춰주는 기능을 broadcasting이라 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "#Same shape\n",
    "m1=torch.FloatTensor([[3,3]])\n",
    "m2=torch.FloatTensor([[2,2]])\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "#Vector + scalar\n",
    "m1=torch.FloatTensor([[1,2]])\n",
    "m2=torch.FloatTensor([3]) #3->[[3,3]]자동으로 변환해서 계산.\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#2 x 1 vector + 1 x 2 vector\n",
    "m1=torch.FloatTensor([[1,2]])\n",
    "m2=torch.FloatTensor([[3],[4]]) #둘다 2x2로 변환해서 계산.\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication vs Matrix Multiplication\n",
    "- 딥러닝은 행렬곱이 많이 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "Mul vs Matmul\n",
      "-----------\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('-----------')\n",
    "print('Mul vs Matmul')\n",
    "print('-----------')\n",
    "m1=torch.FloatTensor([[1,2],[3,4]])\n",
    "m2=torch.FloatTensor([[1],[2]])\n",
    "print('Shape of Matrix 1: ',m1.shape)\n",
    "print('Shape of Matrix 2: ',m2.shape)\n",
    "print(m1.matmul(m2))\n",
    "print(m1*m2)\n",
    "print(m1.mul(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t=torch.FloatTensor([1,2])\n",
    "print(t.mean())# 1,2의 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can only calculate the mean of floating types. Got Long instead.\n"
     ]
    }
   ],
   "source": [
    "#Can't use mean() on integers\n",
    "t=torch.LongTensor([1,2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t=torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean()) # 전체 4개 원소의 평균\n",
    "print(t.mean(dim=0)) #0차원에 대한 평균, 각 열벡터 내에서의 평균\n",
    "print(t.mean(dim=1)) #1치원에 대한 평균, 각 행벡터 내에서의 평균\n",
    "print(t.mean(dim=-1)) #마지막 차원에 대한 평균이므로 1차원에 대한 평균과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t=torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum())\n",
    "print(t.sum(dim=0))# 이것도 mean이랑 같이 열 내부 원자끼리 합\n",
    "print(t.sum(dim=1))# 행 내부 원자끼리 합\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max and Argmax\n",
    "- max는 최댓값, Argmax는 최댓값의 인덱스 값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(t.max()) #4개 원소중 가장 큰 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([3., 4.]), tensor([1, 1]))\n",
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=0)) #max만 구해도 argmax값을 같이 리턴해준다.\n",
    "print('Max: ',t.max(dim=0)[0])\n",
    "print('Argmax: ',t.max(dim=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2., 4.]), tensor([1, 1]))\n",
      "(tensor([2., 4.]), tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=1))\n",
    "print(t.max(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
